
# Where's Waldo? â€“ Automated Visual Search using YOLOv11

![Find Waldo Illustration](/assets/images/1.jpg "Find Waldo Illustration")

## ðŸ“œ Overview

This project implements an automated visual search system to detect Waldo in dense illustrations using the YOLOv11 object detection model. Each illustration is split into 640Ã—640 sub-images, with bounding box annotations for Waldo when present. The pipeline is optimized for small-object detection and rare-class scenarios, using tailored hyperparameters and targeted data augmentation.

---

## ðŸ“‚ Project Structure

```bash
where-is-waldo/
â”œâ”€â”€ assets/ # assets for readme
â”‚ â””â”€â”€ images/
â”‚   â””â”€â”€ 1.jpg
â”‚
â”œâ”€â”€ datasets/ # train and val datasets (populated from preprocess.py)
â”‚ â”œâ”€â”€ train/ # 70% of dataset
â”‚ â”‚  â”œâ”€â”€ images/ # jpg files
â”‚ â”‚  â””â”€â”€ labels/ # txt files
â”‚ â””â”€â”€ val/  # 20 % of dataset
â”‚    â”œâ”€â”€ images/ # jpg files
â”‚    â””â”€â”€ labels/ # txt files
â”‚
â”œâ”€â”€ labelled_data/ # raw dataset from kaggle
â”‚ â”œâ”€â”€ images/ # high-res original images
â”‚ â””â”€â”€ labels/ # resp labels of each img from Roboflow
â”‚
â”œâ”€â”€ Models/ # save trained YOLO models from train.py
â”‚
â”œâ”€â”€ tests/ # 10% testing dataset
â”‚    â”œâ”€â”€ input/ # input data for test
â”‚    â””â”€â”€ output/ # output of test
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ customLib.py # python utility functions
â”œâ”€â”€ DataAugmentation # generate training data****
â”œâ”€â”€ inference.py # predict on test data
â”œâ”€â”€ Main # generate training data****
â”œâ”€â”€ Model # generate training data****
â”œâ”€â”€ preprocess.py # preprocess data****
â”œâ”€â”€ README.md 
â”œâ”€â”€ requirements.txt
â””â”€â”€ train.py # python script to train data
```

---

## ðŸš€ Features

1. Tiling of large illustrations into YOLO-compatible sub-images

2. Annotation handling for images using [RoboFLow](https://app.roboflow.com/)

3. YOLOv11n small-object optimization

4. Steps: preprocessing â†’ training â†’ evaluation â†’ inference

---

### Installation

1. **Clone the repository**

   ```bash
   git clone git@github.com:ACM40960/where-is-waldo.git
   cd where-is-waldo

2. **Create a virtual environment** (optional but recommended)

    ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate

3. **Install dependencies**

    ```bash
    pip install -r requirements.txt

4. **Install PyTorch** (choose version for your CUDA)

   ```bash
    pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu118 # Example for CUDA 11.8
    
---

### Dataset Preparation

1. Download [Where's Waldo dataset](https://www.kaggle.com/datasets/residentmario/wheres-waldo) from Kaggle

2. Create labels using Roboflow and place original images and labels under labelled_data/images and labelled_data/labels respectively.

3. Run preprocessing to tile large pages into 640Ã—640 chips with YOLO-format labels.

    ```bash
    python preprocess.py

By default, preprocess.py writes to ./datasets/train/ (change dest_path to ./datasets/val/ for validation split).